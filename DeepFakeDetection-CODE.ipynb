{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Image Detection with ELA and CNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "import itertools\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "from pylab import *\n",
    "import re\n",
    "\n",
    "import keras\n",
    "print(keras.__version__)\n",
    "import tensorflow as tf\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.3\n",
      "790 790\n",
      "2854 2854\n",
      "2283 2283\n",
      "571 571\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 220, 220, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 216, 216, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 108, 108, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 108, 108, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 373248)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               95551744  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 95,580,322\n",
      "Trainable params: 95,580,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_imlist(path):\n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "def convert_to_ela_image(path, quality):\n",
    "    filename = path\n",
    "    resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n",
    "    ELA_filename = filename.split('.')[0] + '.ela.png'\n",
    "    \n",
    "    im = Image.open(filename).convert('RGB')\n",
    "    im.save(resaved_filename, 'JPEG', quality=quality)\n",
    "    resaved_im = Image.open(resaved_filename)\n",
    "    \n",
    "    ela_im = ImageChops.difference(im, resaved_im)\n",
    "    \n",
    "    extrema = ela_im.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
    "    \n",
    "    return ela_im\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sample: Real Image\n",
    "Let's open a real (not-fake) image as a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('datasets/train/real/Au_ani_00001.jpg')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is how it looks like after it is processed with error-level analysis (ELA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_ela_image('datasets/train/real/Au_ani_00001.jpg', 90)\n",
    "Image.open('datasets/train/fake/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg')\n",
    "convert_to_ela_image('datasets/train/fake/Tp_D_NRN_S_N_ani10171_ani00001_12458.jpg', 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data preparation\n",
    "Read dataset and conversion to ELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ela_image(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    \n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image\n",
    "\n",
    "image_size = (224, 224)\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    #return np.array(ela_image(image_path, 90).resize(128, 128))\n",
    "    return np.array(ela_image(image_path, 90).resize(image_size)).flatten() / 255.0\n",
    "X = [] \n",
    "Y = [] \n",
    "\n",
    "import random\n",
    "path = 'Dataset/casia/CASIA1/Au/'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            X.append(prepare_image(full_path))\n",
    "            Y.append(1)\n",
    "random.shuffle(X)\n",
    "X = X[:2100]\n",
    "Y = Y[:2100]\n",
    "print(len(X), len(Y))\n",
    "\n",
    "path = 'Dataset/casia/CASIA2/Tp/'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('jpg') or filename.endswith('png'):\n",
    "            full_path = os.path.join(dirname, filename)\n",
    "            X.append(prepare_image(full_path))\n",
    "            Y.append(0)\n",
    "print(len(X), len(Y))\n",
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "X = X.reshape(-1, 224, 224, 3)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "print(len(X_train), len(Y_train))\n",
    "print(len(X_val), len(Y_val))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CNN Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (224, 224, 3)))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'valid', activation = 'relu', input_shape = (224, 224, 3)))\n",
    "    model.add(MaxPool2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    return model\n",
    "model = build_model()\n",
    "model.summary()\n",
    "optimizer = RMSprop(lr=0.0005, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=0,\n",
    "                              patience=2,\n",
    "                              verbose=0, mode='auto')\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy curves for training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(2))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=0,\n",
    "                              patience=2,\n",
    "                              verbose=0, mode='auto')\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "          validation_data = (X_val, Y_val), verbose = 2, callbacks=[early_stopping])\n",
    "\n",
    "# Plot the loss and accuracy curves for training and validation \n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_model_fake_real.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
